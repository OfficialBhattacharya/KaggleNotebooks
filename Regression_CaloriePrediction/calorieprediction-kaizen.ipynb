{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-14T21:15:59.445391Z",
     "iopub.status.busy": "2025-05-14T21:15:59.444990Z",
     "iopub.status.idle": "2025-05-14T21:15:59.784927Z",
     "shell.execute_reply": "2025-05-14T21:15:59.783412Z",
     "shell.execute_reply.started": "2025-05-14T21:15:59.445361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import logging\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train = pd.read_csv(\"/kaggle/input/playground-series-s5e5/train.csv\")\n",
    "    test = pd.read_csv(\"/kaggle/input/playground-series-s5e5/test.csv\")\n",
    "    submission = pd.read_csv(\"/kaggle/input/playground-series-s5e5/sample_submission.csv\")\n",
    "    return train, test, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train, test):\n",
    "    train['Sex'] = train['Sex'].map({'male': 1, 'female': 0})\n",
    "    test['Sex'] = test['Sex'].map({'male': 1, 'female': 0})\n",
    "    train = train.drop_duplicates(subset=train.columns).reset_index(drop=True)\n",
    "    train = train.groupby(['Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp'])['Calories'].min().reset_index()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T21:06:50.956204Z",
     "iopub.status.busy": "2025-05-14T21:06:50.955889Z",
     "iopub.status.idle": "2025-05-14T21:06:51.114348Z",
     "shell.execute_reply": "2025-05-14T21:06:51.113270Z",
     "shell.execute_reply.started": "2025-05-14T21:06:50.956172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"Age\",\n",
    "    \"Height\",\n",
    "    \"Weight\",\n",
    "    \"Duration\",\n",
    "    \"Heart_Rate\",\n",
    "    \"Body_Temp\",\n",
    "    \"Calories\",\n",
    "    \"BMR\",\n",
    "    'Metabolic_Efficiency',\n",
    "    'Cardio_Stress',\n",
    "    'Thermic_Effect',\n",
    "    'Power_Output',\n",
    "    'BVI',\n",
    "    'Age_Adj_Intensity',\n",
    "    'Gender_Metabolic',\n",
    "    'HR_Drift',\n",
    "    'BCI',\n",
    "    'Thermal_Work',\n",
    "    'Temp_Binary',\n",
    "    'HeartRate_Binary',\n",
    "    'Sex'\n",
    "]\n",
    "test_df=pd.read_csv(\"/kaggle/input/playground-series-s5e5/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Feature Engineering : All Derived Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_features(df, train):\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2\n",
    "    df['Intensity'] = df['Heart_Rate'] / df['Duration']\n",
    "\n",
    "    df['Sex_Reversed'] = 1 - df['Sex']\n",
    "    for dur in df['Duration'].unique():\n",
    "        df[f'HR_Dur_{int(dur)}'] = np.where(df['Duration'] == dur, df['Heart_Rate'], 0)\n",
    "        df[f'Temp_Dur_{int(dur)}'] = np.where(df['Duration'] == dur, df['Body_Temp'], 0)\n",
    "    for age in df['Age'].unique():\n",
    "        df[f'HR_Age_{int(age)}'] = np.where(df['Age'] == age, df['Heart_Rate'], 0)\n",
    "        df[f'Temp_Age_{int(age)}'] = np.where(df['Age'] == age, df['Body_Temp'], 0)\n",
    "\n",
    "    for f1 in ['Duration', 'Heart_Rate', 'Body_Temp']:\n",
    "        for f2 in ['Sex', 'Sex_Reversed']:\n",
    "            df[f'{f1}_x_{f2}'] = df[f1] * df[f2]\n",
    "\n",
    "    for col in ['Height', 'Weight', 'Heart_Rate', 'Body_Temp']:\n",
    "        for agg in ['min', 'max']:\n",
    "            agg_val = train.groupby('Sex')[col].agg(agg).rename(f'Sex_{col}_{agg}')\n",
    "            df = df.merge(agg_val, on='Sex', how='left')\n",
    "\n",
    "    df.drop(columns=['Sex_Reversed'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T21:06:51.116470Z",
     "iopub.status.busy": "2025-05-14T21:06:51.116120Z",
     "iopub.status.idle": "2025-05-14T21:06:51.532824Z",
     "shell.execute_reply": "2025-05-14T21:06:51.531796Z",
     "shell.execute_reply.started": "2025-05-14T21:06:51.116435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 0. Basal Metabolic Index (BMR)\n",
    "train_df['BMR'] = train_df['Weight'] / ((train_df['Height'] / 100) ** 2)\n",
    "test_df['BMR'] = test_df['Weight'] / ((test_df['Height'] / 100) ** 2)\n",
    "\n",
    "# 1. Metabolic Efficiency Index (Combines BMR with active calorie burn factors)\n",
    "train_df['Metabolic_Efficiency'] = train_df['BMR'] * (train_df['Heart_Rate'] / train_df['BMR'].median())\n",
    "test_df['Metabolic_Efficiency'] = test_df['BMR'] * (test_df['Heart_Rate'] / test_df['BMR'].median())\n",
    "\n",
    "# 2. Cardiovascular Stress (Heart rate relative to age-adjusted max)\n",
    "train_df['Cardio_Stress'] = (train_df['Heart_Rate'] / (220 - train_df['Age'])) * train_df['Duration']\n",
    "test_df['Cardio_Stress'] = (test_df['Heart_Rate'] / (220 - test_df['Age'])) * test_df['Duration']\n",
    "\n",
    "# 3. Thermic Effect Ratio (Body temp impact per weight unit)\n",
    "train_df['Thermic_Effect'] = (train_df['Body_Temp'] * 100) / (train_df['Weight'] ** 0.5)\n",
    "test_df['Thermic_Effect'] = (test_df['Body_Temp'] * 100) / (test_df['Weight'] ** 0.5)\n",
    "\n",
    "# 4. Power Output Estimate (Weight-based energy expenditure)\n",
    "train_df['Power_Output'] = train_df['Weight'] * train_df['Duration'] * (train_df['Heart_Rate'] / 1000)\n",
    "test_df['Power_Output'] = test_df['Weight'] * test_df['Duration'] * (test_df['Heart_Rate'] / 1000)\n",
    "\n",
    "# 5. Body Volume Index (Alternative to BMI using cube root)\n",
    "train_df['BVI'] = train_df['Weight'] / ((train_df['Height']/100) ** 3)\n",
    "test_df['BVI'] = test_df['Weight'] / ((test_df['Height']/100) ** 3)\n",
    "\n",
    "# 6. Age-Adjusted Intensity (Duration scaled by life stage)\n",
    "bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "train_df['Age_Adj_Intensity'] = train_df['Duration'] * pd.cut(train_df['Age'], bins).cat.codes\n",
    "test_df['Age_Adj_Intensity'] = test_df['Duration'] * pd.cut(test_df['Age'], bins).cat.codes\n",
    "\n",
    "# 7. Gender-Specific Metabolic Rate (Differentiated energy coefficients)\n",
    "gender_coeff = {'male': 1.67, 'female': 1.55}  # Based on metabolic studies\n",
    "train_df['Gender_Metabolic'] = train_df['Sex'].map(gender_coeff) * train_df['BMR']\n",
    "test_df['Gender_Metabolic'] = test_df['Sex'].map(gender_coeff) * test_df['BMR']\n",
    "\n",
    "# 8. Cardiovascular Drift (Heart rate change per time unit)\n",
    "# Assuming data is sorted chronologically\n",
    "train_df['HR_Drift'] = train_df.groupby('Age')['Heart_Rate'].diff() / train_df['Duration']\n",
    "test_df['HR_Drift'] = test_df.groupby('Age')['Heart_Rate'].diff() / test_df['Duration']\n",
    "\n",
    "# 9. Body Composition Index (Height-weight ratio with age decay)\n",
    "train_df['BCI'] = (train_df['Weight'] * 1000) / (train_df['Height'] ** 1.5) * (1 / (train_df['Age'] ** 0.2))\n",
    "test_df['BCI'] = (test_df['Weight'] * 1000) / (test_df['Height'] ** 1.5) * (1 / (test_df['Age'] ** 0.2))\n",
    "\n",
    "# 10. Thermal Work Capacity (Combined temp and duration impact)\n",
    "train_df['Thermal_Work'] = (train_df['Body_Temp'] ** 2) * np.log1p(train_df['Duration'])\n",
    "test_df['Thermal_Work'] = (test_df['Body_Temp'] ** 2) * np.log1p(test_df['Duration'])\n",
    "\n",
    "# Binary classification based on temperature for train_df and test_df\n",
    "train_df['Temp_Binary'] = np.where(train_df['Body_Temp'] <= 39.5, 0, 1)\n",
    "test_df['Temp_Binary'] = np.where(test_df['Body_Temp'] <= 39.5, 0, 1)\n",
    "\n",
    "# Binary classification based on heart rate for train_df and test_df\n",
    "train_df['HeartRate_Binary'] = np.where(train_df['Heart_Rate'] <= 99.5, 0, 1)\n",
    "test_df['HeartRate_Binary'] = np.where(test_df['Heart_Rate'] <= 99.5, 0, 1)\n",
    "\n",
    "# Derived sex column for train_df and test_df\n",
    "train_df['Sex'] = train_df['Sex'].map({'male': 1, 'female': 0})\n",
    "test_df['Sex'] = test_df['Sex'].map({'male': 1, 'female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T21:06:52.792180Z",
     "iopub.status.busy": "2025-05-14T21:06:52.791829Z",
     "iopub.status.idle": "2025-05-14T21:06:58.196103Z",
     "shell.execute_reply": "2025-05-14T21:06:58.195231Z",
     "shell.execute_reply.started": "2025-05-14T21:06:52.792153Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Original Skew  Transformed Skew\n",
      "Age_Adj_Intensity          1.300348         -0.162279\n",
      "HeartRate_Binary           0.598154          0.598154\n",
      "Power_Output               0.533623         -0.894505\n",
      "Age                        0.436397          0.436397\n",
      "BVI                        0.399564          0.399564\n",
      "Cardio_Stress              0.330227          0.330227\n",
      "Weight                     0.211194          0.211194\n",
      "BCI                        0.196546          0.196546\n",
      "Thermic_Effect             0.193205          0.193205\n",
      "Metabolic_Efficiency       0.155355          0.155355\n",
      "Height                     0.051777          0.051777\n",
      "Gender_Metabolic           0.041921          0.041921\n",
      "Duration                   0.026259          0.026259\n",
      "Sex                        0.003845          0.003845\n",
      "BMR                       -0.003291         -0.003291\n",
      "Heart_Rate                -0.005668         -0.005668\n",
      "Thermal_Work              -0.809934         -0.312075\n",
      "Body_Temp                 -1.022361         -0.165926\n",
      "Temp_Binary               -1.277665         -1.277665\n",
      "HR_Drift                  -4.894215          3.984836\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select numerical columns\n",
    "numeric_cols = [col for col in numerical_features if col != \"Calories\"]\n",
    "\n",
    "# Step 2: Calculate original skewness on train\n",
    "original_skewness = train_df[numeric_cols].skew().sort_values(ascending=False)\n",
    "\n",
    "# Step 3: Initialize transformed DataFrames\n",
    "train_df_transformed = train_df.copy()\n",
    "test_df_transformed = test_df.copy()\n",
    "\n",
    "# Store transformers for each column\n",
    "transformers = {}\n",
    "\n",
    "# Step 4: Apply skewness correction based on train_df\n",
    "for col in numeric_cols:\n",
    "    if train_df[col].nunique() <= 1:\n",
    "        continue\n",
    "    \n",
    "    if original_skewness[col] > 0.5:  # Right skew\n",
    "        if (train_df[col] > 0).all():\n",
    "            # Log transform\n",
    "            train_df_transformed[col] = np.log1p(train_df[col])\n",
    "            test_df_transformed[col] = np.log1p(test_df[col])\n",
    "        else:\n",
    "            # Yeo-Johnson (handles zero/neg)\n",
    "            pt = PowerTransformer(method='yeo-johnson')\n",
    "            train_df_transformed[col] = pt.fit_transform(train_df[[col]])\n",
    "            test_df_transformed[col] = pt.transform(test_df[[col]])\n",
    "            transformers[col] = pt\n",
    "    elif original_skewness[col] < -0.5:  # Left skew\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "        train_df_transformed[col] = pt.fit_transform(train_df[[col]])\n",
    "        test_df_transformed[col] = pt.transform(test_df[[col]])\n",
    "        transformers[col] = pt\n",
    "\n",
    "# Step 5: Calculate skewness after transformation\n",
    "transformed_skewness = train_df_transformed[numeric_cols].skew().sort_values(ascending=False)\n",
    "\n",
    "# Step 6: Print comparison\n",
    "skew_df = pd.DataFrame({\n",
    "    'Original Skew': original_skewness,\n",
    "    'Transformed Skew': transformed_skewness\n",
    "}).sort_values(by='Original Skew', ascending=False)\n",
    "\n",
    "print(skew_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T21:06:58.197772Z",
     "iopub.status.busy": "2025-05-14T21:06:58.197429Z",
     "iopub.status.idle": "2025-05-14T21:07:00.041162Z",
     "shell.execute_reply": "2025-05-14T21:07:00.040379Z",
     "shell.execute_reply.started": "2025-05-14T21:06:58.197745Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make copies to avoid changing the original\n",
    "cleaned_train_df =train_df_transformed.copy()\n",
    "cleaned_test_df = test_df_transformed.copy()\n",
    "\n",
    "# Select numerical columns only (excluding any non-numeric or non-relevant columns)\n",
    "numeric_cols = [col for col in numerical_features if col != \"Calories\"]\n",
    "\n",
    "# Remove outliers using IQR for both train_df and test_df\n",
    "for col in numeric_cols:\n",
    "    # Train set\n",
    "    Q1_train = cleaned_train_df[col].quantile(0.25)\n",
    "    Q3_train = cleaned_train_df[col].quantile(0.75)\n",
    "    IQR_train = Q3_train - Q1_train\n",
    "    lower_bound_train = Q1_train - 1.5 * IQR_train\n",
    "    upper_bound_train = Q3_train + 1.5 * IQR_train\n",
    "    cleaned_train_df = cleaned_train_df[(cleaned_train_df[col] >= lower_bound_train) & (cleaned_train_df[col] <= upper_bound_train)]\n",
    "\n",
    "\n",
    "# Binary classification based on temperature for train_df and test_df\n",
    "cleaned_test_df=test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def align_columns(train, test):\n",
    "    common_cols = [col for col in test.columns if col in train.columns and col != 'Calories']\n",
    "    X = train[common_cols]\n",
    "    y = np.log1p(train['Calories'])\n",
    "    X_test = test[common_cols]\n",
    "    return X, y, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def final_blend(xgb_preds, cat_preds, submission):\n",
    "    final_preds = 0.49 * np.expm1(xgb_preds) + 0.51 * np.expm1(cat_preds)\n",
    "    submission['Calories'] = np.clip(final_preds, 1, 314)\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    logger.info(\"submission.csv saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def diagnostics(cat_oof, xgb_oof, submission):\n",
    "    plt.hist(np.expm1(cat_oof), bins=50, alpha=0.6, label='CatBoost OOF')\n",
    "    plt.hist(np.expm1(xgb_oof), bins=50, alpha=0.6, label='XGBoost OOF')\n",
    "    plt.title(\"OOF Prediction Distribution\")\n",
    "    plt.xlabel(\"Calories\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    logger.info(\"\\nFinal Submission Preview:\")\n",
    "    logger.info(submission.describe())\n",
    "    logger.info(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    train, test, submission = load_data()\n",
    "    train, test = preprocess_data(train, test)\n",
    "    train = add_features(train, train)\n",
    "    test = add_features(test, train)\n",
    "    X, y, X_test = align_columns(train, test)\n",
    "\n",
    "    cat_preds, cat_oof = train_catboost(X, y, X_test)\n",
    "    xgb_preds, xgb_oof = train_xgboost(X, y, X_test)\n",
    "\n",
    "    final_blend(xgb_preds, cat_preds, submission)\n",
    "    diagnostics(cat_oof, xgb_oof, submission)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T21:07:17.519854Z",
     "iopub.status.busy": "2025-05-14T21:07:17.519385Z",
     "iopub.status.idle": "2025-05-14T21:07:57.649708Z",
     "shell.execute_reply": "2025-05-14T21:07:57.648583Z",
     "shell.execute_reply.started": "2025-05-14T21:07:17.519819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model:   0%|                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:42.93418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [21:07:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mae:2.83631\n",
      "[400]\tvalidation_0-mae:2.66417\n",
      "[600]\tvalidation_0-mae:2.60440\n",
      "[800]\tvalidation_0-mae:2.57861\n",
      "[999]\tvalidation_0-mae:2.56201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|█████████████████████████████████████████████████| 1/1 [00:37<00:00, 37.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "X = cleaned_train_df.drop(columns=['Calories', 'id'])\n",
    "y = cleaned_train_df['Calories']\n",
    "\n",
    "# Step 2: Split data into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Initialize the XGBoost model\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',  # Regression task\n",
    "    colsample_bytree=0.3,          # Subsample ratio of columns\n",
    "    learning_rate=0.1,             # Step size at each iteration\n",
    "    max_depth=5,                   # Maximum depth of a tree\n",
    "    alpha=10,                      # L2 regularization term\n",
    "    n_estimators=1000,             # Number of trees\n",
    "    random_state=42,\n",
    "    verbose=200  # Set verbose to get more detailed output\n",
    ")\n",
    "\n",
    "# Step 4: Train the model with tqdm for progress tracking\n",
    "for _ in tqdm(range(1), desc=\"Training Model\", ncols=100):\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
    "              eval_metric=\"mae\", early_stopping_rounds=50, verbose=200)\n",
    "\n",
    "# Step 5: Prepare test data (remove 'id' column from test_df)\n",
    "X_test_df = cleaned_test_df.drop(columns=['id'])  # Exclude id from features\n",
    "y_test_pred = model.predict(X_test_df)  # Predictions for test_df\n",
    "\n",
    "# Step 6: Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],  # 'id' column from test_df\n",
    "    'Calories': y_test_pred.clip(0)   # Predictions for 'Calories'\n",
    "})\n",
    "\n",
    "# Step 7: Save the submission to a CSV file\n",
    "submission.to_csv('submission_0.csv', index=False)\n",
    "print(\"Submission file 'submission.csv' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_catboost(X, y, X_test):\n",
    "    bins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "    duration_bins = bins.fit_transform(X[['Duration']]).astype(int).flatten()\n",
    "\n",
    "    cat_params = {\n",
    "        'iterations': 2500,\n",
    "        'learning_rate': 0.02,\n",
    "        'depth': 10,\n",
    "        'loss_function': 'RMSE',\n",
    "        'l2_leaf_reg': 3,\n",
    "        'random_seed': 42,\n",
    "        'eval_metric': 'RMSE',\n",
    "        'early_stopping_rounds': 200,\n",
    "        'cat_features': ['Sex'],\n",
    "        'verbose': 0,\n",
    "        'task_type': 'GPU'\n",
    "    }\n",
    "\n",
    "    cat_preds = np.zeros(len(X_test))\n",
    "    cat_oof = np.zeros(len(X))\n",
    "    cat_scores = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, duration_bins)):\n",
    "        model = CatBoostRegressor(**cat_params)\n",
    "        model.fit(X.iloc[train_idx], y.iloc[train_idx], eval_set=(X.iloc[val_idx], y.iloc[val_idx]), use_best_model=True)\n",
    "        cat_oof[val_idx] = model.predict(X.iloc[val_idx])\n",
    "        cat_preds += model.predict(X_test) / skf.n_splits\n",
    "        fold_score = np.sqrt(mean_squared_log_error(np.expm1(y.iloc[val_idx]), np.expm1(cat_oof[val_idx])))\n",
    "        logger.info(f\"Fold {fold+1} - CatBoost RMSLE: {fold_score:.5f}\")\n",
    "        cat_scores.append(fold_score)\n",
    "    logger.info(f\"CatBoost Mean RMSLE: {np.mean(cat_scores):.5f}\")\n",
    "    return cat_preds, cat_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_xgboost(X, y, X_test):\n",
    "    X_xgb = X.copy()\n",
    "    X_test_xgb = X_test.copy()\n",
    "    X_xgb['Sex'] = X_xgb['Sex'].astype(int)\n",
    "    X_test_xgb['Sex'] = X_test_xgb['Sex'].astype(int)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_oof = np.zeros(len(X))\n",
    "    xgb_preds = np.zeros(len(X_test))\n",
    "    xgb_scores = []\n",
    "\n",
    "    xgb_params = {\n",
    "        'max_depth': 9,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 3000,\n",
    "        'learning_rate': 0.01,\n",
    "        'gamma': 0.01,\n",
    "        'max_delta_step': 2,\n",
    "        'eval_metric': 'rmse',\n",
    "        'enable_categorical': False,\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 100,\n",
    "        'tree_method': 'gpu_hist'\n",
    "    }\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_xgb)):\n",
    "        model = XGBRegressor(**xgb_params)\n",
    "        model.fit(X_xgb.iloc[train_idx], y.iloc[train_idx], eval_set=[(X_xgb.iloc[val_idx], y.iloc[val_idx])], verbose=False)\n",
    "        xgb_oof[val_idx] = model.predict(X_xgb.iloc[val_idx])\n",
    "        xgb_preds += model.predict(X_test_xgb) / kf.n_splits\n",
    "        fold_score = np.sqrt(mean_squared_log_error(np.expm1(y.iloc[val_idx]), np.expm1(xgb_oof[val_idx])))\n",
    "        logger.info(f\"Fold {fold+1} - XGBoost RMSLE: {fold_score:.5f}\")\n",
    "        xgb_scores.append(fold_score)\n",
    "    logger.info(f\"XGBoost Mean RMSLE: {np.mean(xgb_scores):.5f}\")\n",
    "    return xgb_preds, xgb_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # === Final Blend (Weighted Average) ===\n",
    "# final_preds = 0.49 * np.expm1(xgb_preds) + 0.51 * np.expm1(cat_preds)\n",
    "# submission['Calories'] = np.clip(final_preds, 1, 314)\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\"\\n submission.csv saved \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # === Diagnostics ===\n",
    "# plt.hist(np.expm1(cat_oof), bins=50, alpha=0.6, label='CatBoost OOF')\n",
    "# plt.hist(np.expm1(xgb_oof), bins=50, alpha=0.6, label='XGBoost OOF')\n",
    "# plt.title(\"OOF Prediction Distribution\")\n",
    "# plt.xlabel(\"Calories\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# print(\"\\n Final Submission Preview:\")\n",
    "# print(submission.describe())\n",
    "# print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
